---
title: Generative Adversarial Nets
excerpt:

categories:
  - Paper
tags:
  - Computer Vision
  - Generative Model
  - GAN
use_math: true
toc: true
toc_sticky: true
last_modified_at: 2021-09-11T14:50:00-05:00
---

**Paper Link** : [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661v1.pdf)

# Abstract

Generative Adversarial Network는 크게 두 가지 모델로 구성된다.

- 데이터의 분포를 모사하는 Generative Model $G$
- sample이 $G$를 통해서 생성되었는지, 훈련 데이터셋으로부터 나왔는지를 구분하는 Discriminative Model $D$

이들 중 핵심이라고 할 수 있는 $G$의 훈련 과정은 $D$가 sample에 대하여 잘못된 판단을 하도록 유도하는 것이다.
<br/>GAN은 두 플레이어 간의 minimax 게임과 유사한 형태라고 할 수 있다.
<br/>임의의 함수 $G$와 $D$의 공간에서 **$G$가 훈련 데이터의 분포를 모사**하고 **$D$는 어떤 sample이 들어오건 $\frac{1}{2}$라는 확률을 출력**하게 된다.
<br/>그리고 이것이 바로 GAN의 unique solution이 된다.
<br/>$G$와 $D$는 Multilayer Perceptron으로 정의되어 있으며, 모두 Backpropogation을 통해 훈련이 가능하다.
<br/>또한 훈련 과정이나 sampled을 생성하는 과정에서 Markov Chain과 같은 다른 어떤 추가적인 방법도 필요하지 않다.
<br/>
<br/>

# Introduction

기존의 Generative Model들은 다음과 같은 문제들로 인하여 큰 주목을 받지 못하였음.

- Maximum Likelihood Estimation과 이에 관련된 다른 방법론으로부터 생겨난 Probablistic Computation을 Approximate 하는 것의 어려움
- Generative context에서 Linear Unit의 이점을 활용하는 것의 어려움

그리고, 이러한 문제를 해결하기 위해 새로운 Generative Model인 GAN을 제시한다.
<br/>
Adversarial Net 프레임워크에서는 Generative Model이 **경쟁**하며 학습을 진행한다.
<br/> 즉, Discriminative Model은 sample이 data distribution으로부터 나왔는지, model distribution으로부터 나왔는지를 학습한다.
<br/> Generative Model은 위조지폐를 만들며 최대한 적발되지 않으려 노력하는 위조지폐범에 비유할 수 있고, Discriminative Model은 이러한 위조지폐를 찾아내려 하는 경찰에 비유할 수 있다.
<br/> 이러한 경쟁 과정은 위조지폐(Generated Sample)를 더 이상 구분할 수 없을 때까지 서로의 성능을 향상시키는 방식으로 진행된다.
<br/> 물론 다른 방법론들도 가능하겠지만, 본 논문에서는 Multilayer Perceptron으로 구성된 Generative Model이 Random Noise를 입력으로 받아서 sample을 생성하고, 마찬가지고 MLP로 구성된 Discriminative Model이 이를 구분하는 특수한 케이스에 대하여 살펴본다.

<br/>
<br/>

# Adversarial Nets

데이터 $x$에 대한 Generator의 확률 분포 $p_g$를 학습하기 위하여 input noise 변수에 대한 prior인 $p_z(z)$를 정의한다. 다음으로, data space에 대한 mapping을 $G(z;\theta_g)$로 나타낸다. 이 때, $G$는 파라미터 $\theta_g$에 대하여 미분가능한 함수이며 MLP로 구성되어 있다.
<br/> 또한, 두 번째 MLP인 $D(x;\theta_d)$를 정의하며 이들은 하나의 scalar를 출력한다. $D(x)$는 $x$가 $p_g$가 아닌 데이터로부터 나올 확률을 나타낸다.
<br/> 이제 $D$가 실제 데이터와 $G$로부터 생성된 데이터를 잘 구분할 수 있도록 학습을 진행한다. 동시에, $G$는 $\log{(1-D(G(z)))}$를 최소화하도록 훈련시킨다.
<br/> 정리하자면, $D$와 $G$는 value function $V(G, D)$에 대하여 일종의 two player minimax game을 수행하는 것이라고 볼 수 있다.
<br/> 수식은 다음과 같다.
<br/>

$$\min_G \max_D V(D, G) = \mathbb{E}_ {x \sim p\_{data}(x)}[ \log {D(x)}] + \mathbb{E}_ {z \sim p_{z}(z)}[ \log {(1-D(G(z)))}]$$

<br/> 하지만 위의 수식을 실제로 적용하게 되면 $G$가 학습할만큼 충분한 gradient가 공급이 되지 않는다. $G$의 성능이 제대로 나오지 않는 학습 초기에는 $G$로부터 생성된 sample이 training data와는 확연하게 다르기 때문에 $D$는 이들을 높은 confidence로 구분할 수 있다. 그리고 **이러한 경우 $\log{(1-D(G(z)))}$는 saturate된다**.
<br/>
이러한 문제를 해결하기 위해서, $G$가 $\log{(1-D(G(z)))}$를 최소화하도록 훈련하는 것이 아니라 $\log{D(G(z))}$를 최대화하도록 한다.
이렇게 식을 변경할 경우 학습에 초반부에서도 충분한 양의 gradient를 공급하게 된다.
<br/>
<br/>
<br/>
![image](https://user-images.githubusercontent.com/25663769/132948483-592d1155-9546-40c8-a3ce-e841d9aa7677.png)
<br/>
<br/>
위의 Figure를 통하여 훈련 과정에 대해 직관적으로 이해를 할 수 있다.

- $D$가 파란색 점선, 실제 데이터 분포가 검은색 점선, 생성된 분포 $p_g$가 초록색 실선이라 보면 된다.
- 그리고 두 개의 수평선 중 아래는 $z$가 샘플링되는 domain이고, 위의 수평선은 $x$의 domain이다.
- 아래에서 위로 향하는 여러 직선들은 mapping인 $x=G(z)$가 input sample들을 어떻게 non-uniform distribution인 $p_g$로 변환하는지를 나타낸다.
- $G$는 밀도가 높은 부분에서 수축하고, $p_g$의 밀도가 낮은 부분에서 확장된다.

이제 (a)를 보면, 실제 분포와 생성된 분포 사이의 차이가 클 뿐만 아니라 $D$의 성능 역시 그다지 좋지 않은 것을 확인할 수 있다.
<br/> (b)에서는 (a)에서 나타난 $D$의 불안정성이 어느정도 개선된 것을 확인할 수 있다.
<br/> 다음으로 (c)에서는 학습이 진행되며 $G$ 역시 실제 데이터의 분포를 나름 잘 모방하고 있는 것을 볼 수 있다.
<br/> 마지막으로 (d)단계에서는 실제 데이터와 생성된 데이터의 분포가 거의 동일해지며, 이에 따라 $D$는 이 둘을 구분할 수 없게 된다. 즉 $D(x)=\frac{1}{2}$가 된다.

<br/>
<br/>

# Advantages and Disadvantages

- **Advantages**
  - Markov Chain이 필요하지 않다.
  - gradient를 얻기 위해 backpropogation만 수행하면 된다.
  - 학습 과정에서 별도의 추론이 필요하지 않다.
  - 다양한 함수와 결합이 가능하다.
  - Generator는 데이터가 아닌 Discriminator로부터 흘러오는 gradient를 통해서만 업데이트 된다.
  - 기존의 방법들이 blurry한 이미지를 생성하는 반면, GAN은 보다 sharp한 이미지를 생성한다.
- **Disadvantages**
  - $p_g(x)$에 대한 명시적인 표현이 없다.
  - $G$와 $D$는 훈련하는 동안 반드시 잘 synchronized되어야 한다.
    - $G$의 성능이 $D$를 심하게 앞서는 경우 $G$가 $\mathbf{z}$를 뭉게놓을 수 있기 때문.
